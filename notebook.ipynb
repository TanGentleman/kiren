{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi Kiren! This is a \"notebook\" that is useful for getting comfier with both Python + real-world research!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pubmed_tools.core.client import PubMedClient\n",
    "from pubmed_tools.parsers.article import ArticleParser\n",
    "from pubmed_tools.exporters.pdf_exporter import PDFExporter\n",
    "from pubmed_tools.exporters.csv_exporter import CSVExporter\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Initialize components\n",
    "client = PubMedClient()\n",
    "parser = ArticleParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_QUERY = \"chunking memory\"\n",
    "# Configuration settings\n",
    "CONFIG = {\n",
    "    'exporters': {\n",
    "        'pdf': {\n",
    "            'enabled': True,\n",
    "            'auto_open': True,\n",
    "            'exporter': PDFExporter(),\n",
    "        },\n",
    "        'csv': {\n",
    "            'enabled': False,\n",
    "            'auto_open': True,\n",
    "            'exporter': CSVExporter(),\n",
    "        },\n",
    "    },\n",
    "    'truncate_articles': {\n",
    "        'enabled': False,\n",
    "        'count': 2,\n",
    "    }\n",
    "}\n",
    "\n",
    "def open_file(filename: str) -> None:\n",
    "    \"\"\"Opens a file using the system's default application.\n",
    "\n",
    "    Args:\n",
    "        filename: Path to the file to open\n",
    "\n",
    "    Note:\n",
    "        This is platform-dependent and is only tested on macOS.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"File not found: {filename}\")\n",
    "\n",
    "    valid_formats = ['.pdf', '.csv', '.xlsx']\n",
    "    file_ext = os.path.splitext(filename.lower())[1]\n",
    "    if file_ext not in valid_formats:\n",
    "        raise ValueError(\n",
    "            f\"File must be one of {valid_formats}, got: {filename}\")\n",
    "    subprocess.Popen(f\"open {filename}\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = DEFAULT_QUERY\n",
    "\n",
    "# Search and fetch articles\n",
    "results = client.search(query)\n",
    "id_list = results[\"id_list\"]\n",
    "details = client.fetch_details(id_list)\n",
    "\n",
    "# Parse articles\n",
    "parsed_articles = parser.parse_all_details(details)\n",
    "if not parsed_articles:\n",
    "    print(\"No articles found\")\n",
    "elif CONFIG['truncate_articles']['enabled']:\n",
    "    parsed_articles = parsed_articles[:CONFIG['truncate_articles']['count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to output.pdf\n"
     ]
    }
   ],
   "source": [
    "# Export to different formats\n",
    "exported_files = {}\n",
    "for format_name, settings in CONFIG['exporters'].items():\n",
    "    if settings['enabled']:\n",
    "        filename = f\"output.{format_name}\"\n",
    "        settings['exporter'].export(parsed_articles, filename)\n",
    "        exported_files[format_name] = filename\n",
    "        print(f\"Exported to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_file(exported_files['pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Chunk Duration Limits the Learning of Multiword Chunks: Behavioral and Electroencephalogram Evidence from Statistical Learning.',\n",
       "  'abstract': \"Language comprehension involves the grouping of words into larger multiword chunks. This is required to recode information into sparser representations to mitigate memory limitations and counteract forgetting. It has been suggested that electrophysiological processing time windows constrain the formation of these units. Specifically, the period of rhythmic neural activity (i.e., slow-frequency neural oscillations) may set an upper limit of 2-3 sec. Here, we assess whether learning of new multiword chunks is also affected by this neural limit. We applied an auditory statistical learning paradigm of an artificial language while manipulating the duration of to-be-learnt chunks. Participants listened to isochronous sequences of disyllabic pseudowords from which they could learn hidden three-word chunks based on transitional probabilities. We presented chunks of 1.95, 2.55, and 3.15 sec that were created by varying the pause interval between pseudowords. In a first behavioral experiment, we tested learning using an implicit target detection task. We found better learning for chunks of 2.55 sec as compared to longer durations in line with an upper limit of the proposed time constraint. In a second experiment, we recorded participants' electroencephalogram during the exposure phase to use frequency tagging as a neural index of statistical learning. Extending the behavioral findings, results show a significant decline in neural tracking for chunks exceeding 3 sec as compared to both shorter durations. Overall, we suggest that language learning is constrained by endogenous time constraints, possibly reflecting electrophysiological processing windows.\",\n",
       "  'authors': ['Lena Henke', 'Lars Meyer'],\n",
       "  'publication_date': {'year': '2024', 'month': '10', 'day': '04'},\n",
       "  'pmid': '39382964'},\n",
       " {'title': 'EXPRESS: Investigating a Metrical Hebb Effect for lists of words.',\n",
       "  'abstract': 'In four experiments, we describe the first finding of a Metrical Hebb Effect. Participants are shown to exhibit a Hebb Repetition Effect for repeating, list-wide stress patterns across sequences of familiar words, even though the lexical items within the \"repeating\" lists do not themselves repeat. Experiment 1 established the presence of a Hebb effect for metrical patterns, demonstrating significant learning of list-wide metrical patterns over successive presentations. Experiment 2 investigated the effect\\'s longevity, showing persistence of learned metrical information after a spacing of three non-repeating lists. Experiment 3 revealed that the effect did not persist over a longer spacing, of eight intervening lists. Experiment 4 investigated the learning mechanism, suggesting that chunking, rather than item-position binding, might account for the observed learning of metrical patterns. The authors propose that metrical-pattern learning represents a process of gradual integration of sequences of weak and strong stress accents, into higher-level units representing the stress patterns within, and across, words. We briefly discuss some implications of the Metrical Hebb Effect for phonological word-form learning, and for speech perception and production.',\n",
       "  'authors': ['Andrew Paice',\n",
       "   'Andrew Johnson',\n",
       "   'Rebecca Legg',\n",
       "   'Eleonore Smalle',\n",
       "   'Mike Page'],\n",
       "  'publication_date': {'year': '2024', 'month': '09', 'day': '13'},\n",
       "  'pmid': '39268671'},\n",
       " {'title': \"Co-production of the 'EPIC' multidimensional tool-kit to support neurodivergent children and young people at home and school: a feasibility and pilot study.\",\n",
       "  'abstract': \"BACKGROUND: Interventions focused on cognitive function in neurodivergent children typically focus on single functions, e.g. working memory training. They are often focused on 'deficit' models and lack an emphasis on understanding areas of individual strengths and difficulties as a prerequisite to appropriate support. The multidimensional nature and phenotypic variability of cognitive profiles in these children indicate a need for a multicomponent-tailored intervention programme focused on understanding and supporting an individual child's cognitive functioning. AIMS: The 'EPIC' intervention (Edinburgh Psychoeducation Intervention for Children and Young People) is focused on improving cognition, learning and behaviour in neurodivergent children such as those with attention deficit hyperactivity disorder (ADHD) or who are autistic. Building on our previous co-production work, this study aimed to use a participatory methods approach to develop EPIC practices and materials in relation to our key principles which include psychoeducation, multicomponent, individualised approach, strengths and difficulties profiling and pairing of a child's individual strengths and difficulties with internal and external strategies. We also set out to assess the feasibility and acceptability of EPIC, and pilot this novel tool-kit intervention with neurodivergent children and their parents and teachers. METHODS: The intervention practices, materials and strategies of EPIC were co-produced with neurodivergent children, their parents, teachers and clinicians taking a strengths and difficulties approach. Identification of psychoeducation activities and strategy practices (e.g. mind-maps, chunking), testing of feasibility and collection of pilot data were conducted over a bi-weekly 8-week programme. Eleven neurodivergent children aged 7 to 12 completed the 16-session individualised programme. Acceptability and feasibility were ascertained via qualitative reports elicited within child and teacher interviews and child ratings of enjoyment. Pilot evaluation data was collected pre- and post-intervention participation, and across cognitive assessments (CANTAB, BRIEF), educational attainment (WIAT) and parent and teacher questionnaires measuring clinical symptoms and behaviour (Conners, AQ, SDQ, self-perception). Data was compared with a matched neurodivergent treatment-as-usual control group (N\\u2009=\\u20099). RESULTS: The co-produced EPIC intervention was both feasible to deliver and acceptable to children, parents and their teachers. Pilot data identified that the 8-week intervention improved cognition (short-term and working memory) and literacy (receptive vocabulary, oral word fluency, listening comprehension). Improvements in the intervention group were also found for parent-reported child behavioural difficulties and aggression, and teacher-reported scholastic competence. Effect sizes generated (Cohen's d) ranged from 0.65 to 2.83. Parents reported continuing to use EPIC strategies when interviewed over a year after participating in the programme. CONCLUSION: The current study met our objectives fully. 'EPIC' (Edinburgh Psychoeducation Intervention for Children and Young People) is feasible in home and school contexts and improves a range of aspects of cognition, learning and behaviour in neurodivergent children. Our findings show EPIC is suitable to be assessed within a full-scale trial.\",\n",
       "  'authors': ['Sinead M Rhodes',\n",
       "   'Emily McDougal',\n",
       "   'Christina Efthymiou',\n",
       "   'Tracy M Stewart',\n",
       "   'Josie N Booth'],\n",
       "  'publication_date': {'year': '2024', 'month': '08', 'day': '10'},\n",
       "  'pmid': '39127770'},\n",
       " {'title': 'The role of morphology in novel word learning: a registered report.',\n",
       "  'abstract': \"The majority of the new words that we learn every day as adults are morphologically complex; yet, we do not know much about the role of morphology in novel word learning. In this study, we tackle this issue by comparing the learning of: (i) suffixed novel words (e.g. ); (ii) novel words that end in non-morphological, but frequent letter chunks (e.g. ); and (iii) novel words with non-morphological, low-frequency endings (e.g. ). Words are learned incidentally through sentence reading, while the participants' eye movements are monitored. We show that morphology has a facilitatory role compared with the other two types of novel words, both during learning and in a post-learning recognition memory task. We also showed that participants attributed meaning to word parts (if  is a state of happiness, then  must mean happy), but this process was not specifically triggered by the presence of a suffix ( must also mean happy in  and ), thus suggesting that the brain tends to assume similar meanings for similar words and word parts.\",\n",
       "  'authors': ['Olga Solaja', 'Davide Crepaldi'],\n",
       "  'publication_date': {'year': '2024', 'month': '06', 'day': '26'},\n",
       "  'pmid': '39100156'},\n",
       " {'title': 'Modelling Working Memory Capacity: Is the Magical Number Four, Seven, or Does it Depend on What You Are Counting?',\n",
       "  'abstract': \"Limited attentional capacity is essential to working memory. How its limit should be assessed is a debated issue. Five experiments compare Cowan's 4-units and Pascual-Leone's 7-units models of limited working memory capacity, with presentation time and attention to operative schemes as potential explanations of this discrepancy. Experiments 1a-1c used the Compound Stimuli Visual Information (CSVI) task, with long versus brief presentation. Capacity was estimated with the Bose-Einstein model, assuming a different number of attending acts in each condition. Participants'  estimates in both conditions were highly correlated and the means were not different, indicating that the same capacity is assessed in both conditions. Experiments 2 and 3 used the 5000-msec CSVI, and the Visual Array Task (VAT) in two conditions (5000- vs. 120-msec presentation). Capacity in the VAT was estimated with Morey's Bayesian method. Participants'  estimates in both VAT conditions were correlated, but the mean was higher with long presentation, suggesting that the long condition benefits from recoding or chunking. The  estimate in the CSVI correlated with the short VAT and (to a lesser degree in Exp.2) with the long VAT. The mean estimate of  in the CSVI was one unit more than in the short VAT. We conclude that the CSVI and the short VAT tap the same capacity, one unit of which in the short VAT is allocated to an operative scheme; we discuss how Cowan's and Pascual-Leone's views on limited capacity can be reconciled.\",\n",
       "  'authors': ['Sergio Morra', 'Paola Patella', 'Lorenzo Muscella'],\n",
       "  'publication_date': {'year': '2024', 'month': '07', 'day': '18'},\n",
       "  'pmid': '39035073'},\n",
       " {'title': 'Goal Shifts Structure Memories and Prioritize Event-defining Information in Memory.',\n",
       "  'abstract': \"Every day, we encounter far more information than we could possibly remember. Thus, our memory systems must organize and prioritize the details from an experience that can adaptively guide the storage and retrieval of specific episodic events. Prior work has shown that shifts in internal goal states can function as event boundaries, chunking experiences into distinct and memorable episodes. In addition, at short delays, memory for contextual information at boundaries has been shown to be enhanced compared with items within each event. However, it remains unclear if these memory enhancements are limited to features that signal a meaningful transition between events. To determine how changes in dynamic goal states influence the organization and content of long-term memory, we designed a 2-day experiment in which participants viewed a series of black-and-white objects surrounded by a color border on a two-by-two grid. The location of the object on the grid determined which of two tasks participants performed on a given trial. To examine if distinct types of goal shifts modulate the effects of event segmentation, we changed the border color, the task, or both after every four items in a sequence. We found that goal shifts influenced temporal memory in a manner consistent with the formation of distinct events. However, for subjective memory representations in particular, these effects differed by the type of event boundary. Furthermore, to examine if goal shifts lead to the prioritization of goal-relevant features in longer lasting memories, we tested source memory for each object's color and grid location both immediately and after a 24-hr delay. On the immediate test, boundaries enhanced the memory for all concurrent source features compared with nonboundary items, but only if those boundaries involved a goal shift. In contrast, after a delay, the source memory was selectively enhanced for the feature relevant to the goal shift. These findings suggest that goals can adaptively structure memories by prioritizing contextual features that define a unique episode in memory.\",\n",
       "  'authors': ['Emily T Cowan',\n",
       "   'Avi J Chanales',\n",
       "   'Lila Davachi',\n",
       "   'David Clewett'],\n",
       "  'publication_date': {'year': '2024', 'month': 'Nov', 'day': '01'},\n",
       "  'pmid': '38991135'},\n",
       " {'title': 'GPU optimization techniques to accelerate optiGAN-a particle simulation GAN.',\n",
       "  'abstract': 'The demand for specialized hardware to train AI models has increased in tandem with the increase in the model complexity over the recent years. Graphics processing unit (GPU) is one such hardware that is capable of parallelizing operations performed on a large chunk of data. Companies like Nvidia, AMD, and Google have been constantly scaling-up the hardware performance as fast as they can. Nevertheless, there is still a gap between the required processing power and processing capacity of the hardware. To increase the hardware utilization, the software has to be optimized too. In this paper, we present some general GPU optimization techniques we used to efficiently train the optiGAN model, a Generative Adversarial Network that is capable of generating multidimensional probability distributions of optical photons at the photodetector face in radiation detectors, on an 8GB Nvidia Quadro RTX 4000 GPU. We analyze and compare the performances of all the optimizations based on the execution time and the memory consumed using the Nvidia Nsight Systems profiler tool. The optimizations gave approximately a 4.5x increase in the runtime performance when compared to a naive training on the GPU, without compromising the model performance. Finally we discuss optiGANs future work and how we are planning to scale the model on GPUs.',\n",
       "  'authors': ['Anirudh Srikanth', 'Carlotta Trigila', 'Emilie Roncali'],\n",
       "  'publication_date': {'year': '2024', 'month': '06', 'day': '13'},\n",
       "  'pmid': '38881563'},\n",
       " {'title': 'Updating predictions in a complex repertoire of actions and its neural representation.',\n",
       "  'abstract': 'Even though actions we observe in everyday life seem to unfold in a continuous manner, they are automatically divided into meaningful chunks, that are single actions or segments, which provide information for the formation and updating of internal predictive models. Specifically, boundaries between actions constitute a hub for predictive processing since the prediction of the current action comes to an end and calls for updating of predictions for the next action. In the current study, we investigated neural processes which characterize such boundaries using a repertoire of complex action sequences with a predefined probabilistic structure. Action sequences consisted of actions that started with the hand touching an object (T) and ended with the hand releasing the object (U). These action boundaries were determined using an automatic computer vision algorithm. Participants trained all action sequences by imitating demo videos. Subsequently, they returned for an fMRI session during which the original action sequences were presented in addition to slightly modified versions thereof. Participants completed a post-fMRI memory test to assess the retention of original action sequences. The exchange of individual actions, and thus a violation of action prediction, resulted in increased activation of the action observation network and the anterior insula. At U events, marking the end of an action, increased brain activation in supplementary motor area, striatum, and lingual gyrus was indicative of the retrieval of the previously encoded action repertoire. As expected, brain activation at U events also reflected the predefined probabilistic branching structure of the action repertoire. At T events, marking the beginning of the next action, midline and hippocampal regions were recruited, reflecting the selected prediction of the unfolding action segment. In conclusion, our findings contribute to a better understanding of the various cerebral processes characterizing prediction during the observation of complex action repertoires.',\n",
       "  'authors': ['Rosari Naveena Selvan',\n",
       "   'Minghao Cheng',\n",
       "   'Sophie Siestrup',\n",
       "   'Falko Mecklenbrauck',\n",
       "   'Benjamin Jainta',\n",
       "   'Jennifer Pomp',\n",
       "   'Anoushiravan Zahedi',\n",
       "   'Minija Tamosiunaite',\n",
       "   'Florentin Wörgötter',\n",
       "   'Ricarda I Schubotz'],\n",
       "  'publication_date': {'year': '2024', 'month': '06', 'day': '12'},\n",
       "  'pmid': '38871038'},\n",
       " {'title': 'Spatial-positional associations in short-term memory can vanish in long-term memory.',\n",
       "  'abstract': 'Studies on the SPoARC effect have shown that serial information is spatially processed in working memory. However, it remains unknown whether these spatial-positional associations are durable or only temporary. This study aimed at investigating whether spatialization would persist when a sequence presented repeatedly is expected to be chunked. If chunked, the items could be unified spatially and their spatialization could vanish. Thirty-seven participants performed a spatialization task which was remotely inspired by the Hebb repetition paradigm. A sequence of four stimuli presented individually in the middle of a computer screen was repeated throughout the task. After each sequence, participants had to decide whether a probe belonged to the series using two lateralized response keys. The results showed no spatialization for these repetitive sequences, on average. Moreover, further analysis revealed that the effect was detectable at the beginning of the task, suggesting that the more the sequence was repeated, the less participants spatialized information from left to right. These findings show that associations created in working memory between items and space can vanish in repeated sequences: we discuss the idea that working memory progressively saves on spatialization once a sequence is chunked in long-term memory.',\n",
       "  'authors': ['Morgane Ftaïta',\n",
       "   'Alessandro Guida',\n",
       "   'Michaël Fartoukh',\n",
       "   'Fabien Mathy'],\n",
       "  'publication_date': {'year': '2024', 'month': '06', 'day': '12'},\n",
       "  'pmid': '38867003'},\n",
       " {'title': 'How Time Pressure Modulates Individual Differences in the Functional Connectivity of Chunk Memory in Chess Games.',\n",
       "  'abstract': 'Previous studies on the chess game demonstrated that chess experts strongly rely on the activation of memory chunks to manifest accurate decision-making. Although the chunk memory might be affected by temporal constraints, it is unclear why the performance of chess experts is not significantly dropped under time pressure. In this study, our objective is to examine the variations in cognitive neural mechanisms between chess experts and novices under time pressure. The underlying cognitive neural mechanism was carefully inspected by accessing the chess game performance between 20 local experienced and 20 inexperienced chess players with 1-minute and 5-minute time constraints. In addition, functional near-infrared spectroscopy (fNIRS) recordings were carried out for each individual from the two groups while playing a 1-minute or 5-minute chess game. It was discovered that under temporal constraints, players exhibited different patterns of functional connectivity in frontal-parietal regions, suggesting that temporal stress can enhance segmentation processes in chess games. In particular, the experienced group exhibited significantly enhanced functional connectivity networks under time pressure including the dorsolateral prefrontal cortex, inferior frontal gyrus, supramarginal gyrus, and postcentral gyrus, which demonstrated the important role of the segmentation process for experienced players under time pressure. Our study found that experienced players were able to enhance recall, reorganize, and integrate chunks to improve chess performance under time pressure.',\n",
       "  'authors': ['Chantat Leong', 'Yuwen Lin', 'Juan Zhang', 'Zhen Yuan'],\n",
       "  'publication_date': {'year': '2024', 'month': '06', 'day': '06'},\n",
       "  'pmid': '38851380'},\n",
       " {'title': 'Proactive interference of visual working memory chunks implicates long-term memory.',\n",
       "  'abstract': 'Visual working memory (VWM) is a limited cognitive resource that can be functionally expanded through chunking (Miller, 1956). For example, participants can hold an increasing number of colours in mind as they learn to chunk reliably paired combinations (Brady\\xa0et al.,\\xa02009). We investigated whether this benefit is mediated through the in situ compression of VWM representations (Brady et al.,\\xa02009) or the offloading of chunks to long-term memory (LTM; Huang & Awh, 2018; Ngiam et al., 2019) by asking if a vulnerability of LTM - proactive interference - influences VWM performance. We adapted previous designs using deterministic (Experiment 1, N = 60) and probabilistic pairings (Experiments 2 and 3, N = 64 and 80, respectively), to include colour pairings that swapped in sequence along with pairings that were consistent in sequence. Generally, participants reported colours from consistent pairs more accurately than from swapping pairs, which we designed to drive interference in LTM (Experiments 1 and 2). The error profiles also pointed to proactive interference between swapping pairs in all three experiments. Moreover, participants who had explicit awareness of frequent colour pairings had higher VWM accuracy, and their errors reflected more proactive interference than their unaware counterparts (Experiment 3). This pattern of long-term proactive interference in a VWM task lends support for accounts of VWM chunking that propose LTM offloading.',\n",
       "  'authors': ['Logan Doyle', 'Susanne Ferber', 'Katherine D Duncan'],\n",
       "  'publication_date': {'year': '2024', 'month': '05', 'day': '16'},\n",
       "  'pmid': '38755495'},\n",
       " {'title': 'Behavioral signatures of the rapid recruitment of long-term memory to overcome working memory capacity limits.',\n",
       "  'abstract': 'Working- and long-term memory are often studied in isolation. To better understand the specific limitations of working memory, effort is made to reduce the potential influence of long-term memory on performance in working memory tasks (e.g., asking participants to remember artificial, abstract items rather than familiar real-world objects). However, in everyday life we use working- and long-term memory in tandem. Here, our goal was to characterize how long-term memory can be recruited to circumvent capacity limits in a typical visual working memory task (i.e., remembering colored squares). Prior work has shown that incidental repetitions of working memory arrays often do not improve visual working memory performance - even after dozens of incidental repetitions, working memory performance often shows no improvement for repeated arrays. Here, we used a whole-report working memory task with explicit rather than incidental repetitions of arrays. In contrast to prior work with incidental repetitions, in two behavioral experiments we found that explicit repetitions of arrays yielded robust improvement to working memory performance, even after a single repetition. Participants performed above chance at recognizing repeated arrays in a later long-term memory test, consistent with the idea that long-term memory was used to rapidly improve performance across array repetitions. Finally, we analyzed inter-item response times and we found a response time signature of chunk formation that only emerged after the array was repeated (inter-response time slowing after two to three items); thus, inter-item response times may be useful for examining the coordinated interaction of visual working and long-term memory in future work.',\n",
       "  'authors': ['Kirsten C S Adam', 'Chong Zhao', 'Edward K Vogel'],\n",
       "  'publication_date': {'year': '2024', 'month': '05', 'day': '14'},\n",
       "  'pmid': '38744775'},\n",
       " {'title': 'Grouping in working memory guides chunk formation in long-term memory: Evidence from the Hebb effect.',\n",
       "  'abstract': 'The Hebb effect refers to the improvement in immediate memory performance on a repeated list compared to unrepeated lists. That is, participants create a long-term memory representation over repetitions, on which they can draw in working memory tests. These long-term memory representations are likely formed by chunk acquisition: The whole list becomes integrated into a single unified representation. Previous research suggests that the formation of such chunks is rather inflexible and only occurs when at least the beginning of the list repeats across trials. However, recent work has shown that repetition learning strongly depends on participants recognizing the repeated information. Hence, successful chunk formation may depend on the recognizability of the repeated part of a list, and not on its position in the list. Across six experiments, we compared these two alternatives. We tested immediate serial recall of eight-letter lists, some of which partially repeated across trials. We used different partial-repetition structures, such as repeating only the first half of a list, or only every second item. We manipulated the salience of the repeating structure by spatially grouping and coloring the lists according to the repetition structure. We found that chunk formation is more flexible than previously assumed: Participants learned contiguous repeated sequences regardless of their position within the list, as long as they were able to recognize the repeated structure. Even when the repeated sequence occurred at varying positions over repetitions, learning was preserved when the repeated sequence was made salient by the spatial grouping. These findings suggest that chunk formation requires recognition of which items constitute a repeating group, and demonstrate a close link between grouping of information in working memory, and chunk formation in long-term memory.',\n",
       "  'authors': ['Philipp Musfeld',\n",
       "   'Joscha Dutli',\n",
       "   'Klaus Oberauer',\n",
       "   'Lea M Bartsch'],\n",
       "  'publication_date': {'year': '2024', 'month': '04', 'day': '25'},\n",
       "  'pmid': '38669793'},\n",
       " {'title': 'Distinct brain network organizations between club players and novices under different difficulty levels.',\n",
       "  'abstract': \"SIGNIFICANT: Chunk memory is one of the essential cognitive functions for high-expertise (HE) player to make efficient decisions. However, it remains unknown how the neural mechanisms of chunk memory processes mediate or alter chess players' performance when facing different opponents. AIM: This study aimed at inspecting the significant brain networks associated with chunk memory, which would vary between club players and novices. APPROACH: Functional networks and topological features of 20 club players (HE) and 20 novice players (LE) were compared at different levels of difficulty by means of functional near-infrared spectroscopy. RESULTS: Behavioral performance indicated that the club player group was unaffected by differences in difficulty. Furthermore, the club player group demonstrated functional connectivity among the dorsolateral prefrontal cortex, the frontopolar cortex, the supramarginal gyrus, and the subcentral gyrus, as well as higher clustering coefficients and lower path lengths in the high-difficulty task. CONCLUSIONS: The club player group illustrated significant frontal-parietal functional connectivity patterns and topological characteristics, suggesting enhanced chunking processes for improved chess performance.\",\n",
       "  'authors': ['Chantat Leong', 'Zhiying Zhao', 'Zhen Yuan', 'Bin Liu'],\n",
       "  'publication_date': {'year': '2024', 'month': 'Apr', 'day': ''},\n",
       "  'pmid': '38641879'},\n",
       " {'title': 'Lesions in a songbird vocal circuit increase variability in song syntax.',\n",
       "  'abstract': \"Complex skills like speech and dance are composed of ordered sequences of simpler elements, but the neuronal basis for the syntactic ordering of actions is poorly understood. Birdsong is a learned vocal behavior composed of syntactically ordered syllables, controlled in part by the songbird premotor nucleus HVC (proper name). Here, we test whether one of HVC's recurrent inputs, mMAN (medial magnocellular nucleus of the anterior nidopallium), contributes to sequencing in adult male Bengalese finches (). Bengalese finch song includes several patterns: (1)  comprising stereotyped syllable sequences; (2) , where a given syllable can be followed probabilistically by multiple syllables; and (3) , where individual syllables are repeated variable numbers of times. We found that following bilateral lesions of mMAN, acoustic structure of syllables remained largely intact, but sequencing became more variable, as evidenced by 'breaks' in previously stereotyped chunks, increased uncertainty at branch points, and increased variability in repeat numbers. Our results show that mMAN contributes to the variable sequencing of vocal elements in Bengalese finch song and demonstrate the influence of recurrent projections to HVC. Furthermore, they highlight the utility of species with complex syntax in investigating neuronal control of ordered sequences.\",\n",
       "  'authors': ['Avani Koparkar',\n",
       "   'Timothy L Warren',\n",
       "   'Jonathan D Charlesworth',\n",
       "   'Sooyoon Shin',\n",
       "   'Michael S Brainard',\n",
       "   'Lena Veit'],\n",
       "  'publication_date': {'year': '2024', 'month': '04', 'day': '18'},\n",
       "  'pmid': '38635312'},\n",
       " {'title': 'BRAND: a platform for closed-loop experiments with deep network models.',\n",
       "  'abstract': 'Artificial neural networks (ANNs) are state-of-the-art tools for modeling and decoding neural activity, but deploying them in closed-loop experiments with tight timing constraints is challenging due to their limited support in existing real-time frameworks. Researchers need a platform that fully supports high-level languages for running ANNs (e.g. Python and Julia) while maintaining support for languages that are critical for low-latency data acquisition and processing (e.g. C and C++).To address these needs, we introduce the Backend for Realtime Asynchronous Neural Decoding (BRAND). BRAND comprises Linux processes, termed, which communicate with each other in avia streams of data. Its asynchronous design allows for acquisition, control, and analysis to be executed in parallel on streams of data that may operate at different timescales. BRAND uses Redis, an in-memory database, to send data between nodes, which enables fast inter-process communication and supports 54 different programming languages. Thus, developers can easily deploy existing ANN models in BRAND with minimal implementation changes.In our tests, BRAND achieved <600 microsecond latency between processes when sending large quantities of data (1024 channels of 30 kHz neural data in 1 ms chunks). BRAND runs a brain-computer interface with a recurrent neural network (RNN) decoder with less than 8 ms of latency from neural data input to decoder prediction. In a real-world demonstration of the system, participant T11 in the BrainGate2 clinical trial (ClinicalTrials.gov Identifier: NCT00912041) performed a standard cursor control task, in which 30 kHz signal processing, RNN decoding, task control, and graphics were all executed in BRAND. This system also supports real-time inference with complex latent variable models like Latent Factor Analysis via Dynamical Systems.By providing a framework that is fast, modular, and language-agnostic, BRAND lowers the barriers to integrating the latest tools in neuroscience and machine learning into closed-loop experiments.',\n",
       "  'authors': ['Yahia H Ali',\n",
       "   'Kevin Bodkin',\n",
       "   'Mattia Rigotti-Thompson',\n",
       "   'Kushant Patel',\n",
       "   'Nicholas S Card',\n",
       "   'Bareesh Bhaduri',\n",
       "   'Samuel R Nason-Tomaszewski',\n",
       "   'Domenick M Mifsud',\n",
       "   'Xianda Hou',\n",
       "   'Claire Nicolas',\n",
       "   'Shane Allcroft',\n",
       "   'Leigh R Hochberg',\n",
       "   'Nicholas Au Yong',\n",
       "   'Sergey D Stavisky',\n",
       "   'Lee E Miller',\n",
       "   'David M Brandman',\n",
       "   'Chethan Pandarinath'],\n",
       "  'publication_date': {'year': '2024', 'month': '04', 'day': '17'},\n",
       "  'pmid': '38579696'},\n",
       " {'title': 'DEW: A wavelet approach of rare sound event detection.',\n",
       "  'abstract': \"This paper presents a novel sound event detection (SED) system for rare events occurring in an open environment. Wavelet multiresolution analysis (MRA) is used to decompose the input audio clip of 30 seconds into five levels. Wavelet denoising is then applied on the third and fifth levels of MRA to filter out the background. Significant transitions, which may represent the onset of a rare event, are then estimated in these two levels by combining the peak-finding algorithm with the K-medoids clustering algorithm. The small portions of one-second duration, called 'chunks' are cropped from the input audio signal corresponding to the estimated locations of the significant transitions. Features from these chunks are extracted by the wavelet scattering network (WSN) and are given as input to a support vector machine (SVM) classifier, which classifies them. The proposed SED framework produces an error rate comparable to the SED systems based on convolutional neural network (CNN) architecture. Also, the proposed algorithm is computationally efficient and lightweight as compared to deep learning models, as it has no learnable parameter. It requires only a single epoch of training, which is 5, 10, 200, and 600 times lesser than the models based on CNNs and deep neural networks (DNNs), CNN with long short-term memory (LSTM) network, convolutional recurrent neural network (CRNN), and CNN respectively. The proposed model neither requires concatenation with previous frames for anomaly detection nor any additional training data creation needed for other comparative deep learning models. It needs to check almost 360 times fewer chunks for the presence of rare events than the other baseline systems used for comparison in this paper. All these characteristics make the proposed system suitable for real-time applications on resource-limited devices.\",\n",
       "  'authors': ['Sania Gul', 'Muhammad Salman Khan', 'Ata Ur-Rehman'],\n",
       "  'publication_date': {'year': '2024', 'month': '03', 'day': '28'},\n",
       "  'pmid': '38547253'},\n",
       " {'title': 'Evaluating the Relative Importance of Wordhood Cues Using Statistical Learning.',\n",
       "  'abstract': \"Identifying wordlike units in language is typically done by applying a battery of criteria, though how to weight these criteria with respect to one another is currently unknown. We address this question by investigating whether certain criteria are also used as cues for learning an artificial language-if they are, then perhaps they can be relied on more as trustworthy top-down diagnostics. The two criteria for grammatical wordhood that we consider are a unit's free mobility and its internal immutability. These criteria also map to two cognitive mechanisms that could underlie successful statistical learning: learners might orient themselves around the low transitional probabilities at unit boundaries, or they might seek chunks with high internal transitional probabilities. We find that each criterion has its own facilitatory effect, and learning is best where they both align. This supports the battery-of-criteria approach to diagnosing wordhood, and also suggests that the mechanism behind statistical learning may not be a question of either/or; perhaps the two mechanisms do not compete, but mutually reinforce one\\xa0another.\",\n",
       "  'authors': ['Elizabeth Pankratz', 'Simon Kirby', 'Jennifer Culbertson'],\n",
       "  'publication_date': {'year': '2024', 'month': 'Mar', 'day': ''},\n",
       "  'pmid': '38497523'},\n",
       " {'title': 'Energy-Efficient Sleep Apnea Detection Using a Hyperdimensional Computing Framework Based on Wearable Bracelet Photoplethysmography.',\n",
       "  'abstract': 'OBJECTIVE: Sleep apnea syndrome (SAS) is a common sleep disorder, which has been shown to be an important contributor to major neurocognitive and cardiovascular sequelae. Considering current diagnostic strategies are limited with bulky medical devices and high examination expenses, a large number of cases go undiagnosed. To enable large-scale screening for SAS, wearable photoplethysmography (PPG) technologies have been used as an early detection tool. However, existing algorithms are energy-intensive and require large amounts of memory resources, which are believed to be the major drawbacks for further promotion of wearable devices for SAS detection. METHODS: In this paper, an energy-efficient method of SAS detection based on hyperdimensional computing (HDC) is proposed. Inspired by the phenomenon of chunking in cognitive psychology as a memory mechanism for improving working memory efficiency, we proposed a one-dimensional block local binary pattern (1D-BlockLBP) encoding scheme combined with HDC to preserve dominant dynamical and temporal characteristics of pulse rate signals from wearable PPG devices. RESULTS: Our method achieved 70.17 % accuracy in sleep apnea segment detection, which is comparable with traditional machine learning methods. Additionally, our method achieves up to 67× lower memory footprint, 68× latency reduction, and 93× energy saving on the ARM Cortex-M4 processor. CONCLUSION: The simplicity of hypervector operations in HDC and the novel 1D-BlockLBP encoding effectively preserve pulse rate signal characteristics with high computational efficiency. SIGNIFICANCE: This work provides a scalable solution for long-term home-based monitoring of sleep apnea, enhancing the feasibility of consistent patient care.',\n",
       "  'authors': ['Tian Chen',\n",
       "   'Jingtao Zhang',\n",
       "   'Zeju Xu',\n",
       "   'Stephen J Redmond',\n",
       "   'Nigel H Lovell',\n",
       "   'Guanzheng Liu',\n",
       "   'Changhong Wang'],\n",
       "  'publication_date': {'year': '2024', 'month': '07', 'day': '18'},\n",
       "  'pmid': '38483799'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_articles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
